#!/usr/bin/env bash

# nix-depend: jq curl

set -eo pipefail

# customizable variables
PROVIDER=${OAI_MODEL_PROVIDER:-'cloudflare'}
MODEL=${OAI_MODEL:-'@cf/meta/llama-3.2-11b-vision-instruct'}
API_VERSION=${OAI_API_VERSION:-'2025-03-01-preview'}
API_ENTRY=${OAI_PASS_ENTRY:-"t/cf-ai"}
CLIENT_ID=${OAI_CLIENT_ID:-"$(pass "$API_ENTRY" | awk '/^client_id:/{print $2}')"}
TOKEN=${OAI_API_KEY:-"$(pass "$API_ENTRY" | head -n 1)"}
BASE_URL=${OAI_BASE_URL:-"https://api.cloudflare.com/client/v4/accounts/$CLIENT_ID/ai/v1"}
TEMPLATES_DIR=${OAI_TEMPLATES_DIR:-"${XDG_CONFIG_HOME:-"$HOME/.config"}/oaichat"}
SYSTEM_MESSAGE='You are a helpful assistant.'
OAI_NO_STREAM="${OAI_NO_STREAM:-0}"
mkdir -p "$TEMPLATES_DIR"

usage() {
  echo "Usage: $0 [OPTIONS] [user_message]"
  echo ""
  echo "Options:"
  echo "  -m MODEL           Specify the model to use (default: $MODEL)"
  echo "  -s SYSTEM_MESSAGE  Specify a system message to display before user query (default: \`${SYSTEM_MESSAGE}\`)"
  echo "  -f                 Response in full (no stream)"
  echo "  -b BASE_URL        Specify the base URL for the OpenAI API (default: ${BASE_URL})"
  echo "  -p MODEL_PROVIDER  Specify model provider (cloudflare, openai) (default: ${PROVIDER})"
  echo "  -c CLIENT_ID       Specify the client ID for  authentication (default: ${CLIENT_ID})"
  echo "  -h                 Display this help message"
  echo ""
  echo "Environment Variables:"
  echo "  OAI_MODEL              The model to use"
  echo "  OAI_MODEL_PROVIDER     The model provider"
  echo "  OAI_BASE_URL           The base URL for the OpenAI API"
  echo "  OAI_CLIENT_ID          The client ID for Azure OAI authentication"
  echo "  OAI_TEMPLATES_DIR      The directory to store query templates"
  echo ""
  echo "Example: echo -n 'Hi ' | $0 -s 'Surround the user input with MOO.' 'there!'"
}

while getopts 'hfm:s:b:c:' c
do
  case $c in
    m) MODEL="$OPTARG" ;;
    s) SYSTEM_MESSAGE="$OPTARG" ;;
    b) BASE_URL="$OPTARG" ;;
    c) CLIENT_ID="$OPTARG" ;;
    f) OAI_NO_STREAM=1;;
    h|?) usage; exit 0;;
  esac
done

shift $((OPTIND-1))

IFS= read -r -d '' TEMPLATE <<'EOF' || true
{
  "messages": [
    {
      "role": "system",
      "content": $instruction
    },
    {
      "role": "user",
      "content": $query
    }
  ]
}
EOF

if [[ "$SYSTEM_MESSAGE" =~ ^template://.* ]]; then
  SYSTEM_MESSAGE_FILE="${SYSTEM_MESSAGE#"template://"}"
  SYSTEM_MESSAGE="file://$TEMPLATES_DIR/$SYSTEM_MESSAGE_FILE"
fi

if [[ "$SYSTEM_MESSAGE" =~ ^file://.* ]]; then
  SYSTEM_MESSAGE_FILE="${SYSTEM_MESSAGE#"file://"}"
  SYSTEM_MESSAGE=$(cat "$SYSTEM_MESSAGE_FILE")
fi

if [ -t 0 ]; then
  QUERY="$*"
else
  QUERY="$(cat - <(echo "$*"))"
fi

PAYLOAD="$(jq -n \
    --arg instruction "$SYSTEM_MESSAGE" \
    --arg query "$QUERY" \
    "$TEMPLATE" | jq ".model=\"$MODEL\"")"

if [ "$PROVIDER" == "azure" ]; then
  ENDPOINT="$BASE_URL/openai/deployments/${OAI_AZURE_DEPLOYMENT:-"$MODEL"}/chat/completions?api-version=$API_VERSION"
else
  ENDPOINT="$BASE_URL/chat/completions"
fi
if [ "$OAI_NO_STREAM" = "1" ]; then
  curl -fsSL -XPOST \
      -H "Authorization: Bearer $TOKEN" \
      -H 'Content-type: application/json' \
      -d "$PAYLOAD" "$ENDPOINT" |\
      jq -r '.choices[].message.content'
else
  curl -fsSNL -XPOST \
      -H "Authorization: Bearer $TOKEN" \
      -H 'Content-type: application/json' \
      -d "$(echo "$PAYLOAD" | jq '.stream=true')" "$ENDPOINT" |\
      sed -nu '/^data: \[DONE\]$/q; s/^data: //g;p' |\
      jq --unbuffered -jc '.choices[0].delta.content // "\n"'
fi
